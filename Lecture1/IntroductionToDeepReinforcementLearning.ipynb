{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "050fc920-77de-412b-874d-a270a7c68ba3",
   "metadata": {},
   "source": [
    "# Introduction to Reinforcement Learning üß†ü§ñ\n",
    "\n",
    "Reinforcement Learning (RL) is a subset of Machine Learning in which an agent acquires the ability to navigate and make decisions within an environment through a process of taking actions and observing the subsequent outcomes.\n",
    "\n",
    "##  The Idea\n",
    "Reinforcement Learning operates on the premise that an artificial intelligence agent learns by actively engaging with its environment, experimenting through trial and error. This learning process involves the agent receiving feedback in the form of rewards, whether positive or negative, as a consequence of its actions. This concept mirrors the way we, as humans, naturally learn from our experiences and interactions with the world around us.\n",
    "\n",
    "### Human Example\n",
    "  \n",
    "Let's consider a simple example of Reinforcement Learning using a human interacting with a computer game. In this scenario, the human is the agent, and the game environment provides feedback in the form of scores.\n",
    "\n",
    "1.  **Initialization:**\n",
    "    \n",
    "    -   The human starts playing a game with no prior knowledge of how to win or maximize the score.\n",
    "    -   The game environment represents the context in which the human takes actions.\n",
    "2.  **Taking Actions:**\n",
    "    \n",
    "    -   The human takes actions in the game, such as moving a character, making decisions, or using tools available in the game.\n",
    "    -   Initially, the human's actions may be random, as there is no knowledge of what works best.\n",
    "3.  **Receiving Feedback (Rewards):**\n",
    "    \n",
    "    -   As the human plays, the game environment provides feedback in the form of rewards or penalties.\n",
    "    -   Positive rewards are given for achieving specific objectives, completing tasks, or making successful moves.\n",
    "    -   Negative rewards or penalties are given for making mistakes, losing points, or failing to achieve goals.\n",
    "4.  **Learning from Feedback:**\n",
    "    \n",
    "    -   The human learns from the consequences of their actions. If a certain action leads to a positive outcome (higher score), the likelihood of repeating that action increases.\n",
    "    -   Conversely, if an action results in a negative outcome, the human adjusts their strategy to avoid that action in the future.\n",
    "5.  **Adaptation and Improvement:**\n",
    "    \n",
    "    -   Over time, through a series of interactions, the human adapts their behavior based on the learned experiences and the feedback received.\n",
    "    -   The agent (human) becomes more skilled at the game, making better decisions to maximize the score.\n",
    "6.  **Optimization:**\n",
    "    \n",
    "    -   Through continuous gameplay and learning, the human optimizes their strategy to achieve the highest possible score in the game.\n",
    "\n",
    "Reinforcement Learning is a computational paradigm inspired by how humans and animals learn through interaction with their environment. It formalizes the learning process by framing it as an agent interacting with an environment, taking actions, receiving feedback (rewards or penalties), and adjusting its behavior to maximize cumulative rewards over time.\n",
    "\n",
    "## use cases of Reinforcement Learning\n",
    "\n",
    "**1. Robotics and Automation**\n",
    "\n",
    "RL is being used to develop robots that can perform complex tasks in unstructured or dynamic environments. For example, RL has been used to train robots to grasp objects, navigate through cluttered spaces, and even perform surgery.\n",
    "\n",
    "![Image of Robotic arm performing surgery using reinforcement learning](https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcRfO_knFDN3HwrH40gE22gOIDo3-HXVJvgYFuPPAQRn-7FlFA44SdBk2IARCv4t)\n",
    "Robotic arm performing surgery using reinforcement learning\n",
    "\n",
    "**2. Gaming**\n",
    "\n",
    "RL has revolutionized the gaming industry, enabling the creation of games with more sophisticated and nuanced AI opponents. For example, the game DeepMind AlphaGo defeated the world champion Go player in 2016.\n",
    "\n",
    "![Image of DeepMind AlphaGo playing Go](https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcRklJqPakPxSjtvd1Tc5KJBPxDxw7Ya-fxO15BbuKSlNqLOV-PeJA0zNrOqjTTV)\n",
    "\n",
    "DeepMind AlphaGo playing Go\n",
    "\n",
    "**3. Finance**\n",
    "\n",
    "RL is being used to develop trading algorithms that can make decisions in real-time to maximize profits. For example, the firm Quantopian uses RL to develop trading algorithms for its customers.\n",
    "\n",
    "![Image of Quantopian trading platform](https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcQ7SczEgu4vLS-W7k4ssYBktc8-2U2bRcCrMoxqolct8zc6S5sPUfSy2APEKcmW)\n",
    "\n",
    "Quantopian trading platform\n",
    "\n",
    "**4. Marketing and Advertising**\n",
    "\n",
    "RL is being used to improve the targeting and personalization of marketing campaigns. For example, the company Criteo uses RL to optimize the placement of ads on websites.\n",
    "\n",
    "![Image of Criteo ad placement AI](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQvzpstEt76KDem5T6gxOZV8jNL2-B9rkpYUHqjyZBI4zIXXBdIHBaB4rNvam1f)\n",
    "\n",
    "Criteo ad placement AI\n",
    "\n",
    "**5. Healthcare**\n",
    "\n",
    "RL is being used to develop new treatment plans for patients and to improve the accuracy of medical diagnosis. For example, the company IBM Watson uses RL to analyze medical data and suggest treatment options.\n",
    "\n",
    "![Image of IBM Watson medical diagnosis AI](https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQPX-L_FTYSelQA_4t4tQqDaOOwqJyWT8gtomB3p1UZZxiQJrFVGYRA0ZJwmdhY)\n",
    "\n",
    "IBM Watson medical diagnosis AI\n",
    "\n",
    "**6. Transportation**\n",
    "\n",
    "RL is being used to develop autonomous vehicles that can safely navigate roads and traffic. For example, the company Waymo is using RL to train autonomous vehicles to drive in a variety of environments.\n",
    "\n",
    "![Image of Waymo autonomous vehicle](https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTPrqI7EbnJDQY64AtTxDYb6II426M5yScCRxjEhsljaH0XayLicUKNWHhyHEOm)\n",
    "\n",
    "Waymo autonomous vehicle\n",
    "\n",
    "**7. Energy**\n",
    "\n",
    "RL is being used to optimize the operation of power grids and to develop more efficient energy systems. For example, the company Grid Singularity is using RL to optimize the dispatch of renewable energy sources.\n",
    "\n",
    "**8. Logistics and Supply Chain**\n",
    "\n",
    "RL is being used to optimize the routing of trucks and other vehicles, to manage inventory levels, and to schedule deliveries. For example, the company Amazon is using RL to optimize its delivery service.\n",
    "\n",
    "**9. Natural Language Processing (NLP)**\n",
    "\n",
    "RL is being used to develop NLP models that can understand and respond to human language more effectively. RLHF in NLP refers to using reinforcement learning from human feedback to train natural language processing models. Rather than relying solely on static datasets, models learn interactively from simple human rewards or ratings on their performance.\n",
    "\n",
    "**10. Image and Video Processing**\n",
    "\n",
    "Reinforcement Learning is increasingly employed to enhance the capabilities of computer vision (CV) algorithms, particularly in the domain of image and video processing. By leveraging RL techniques, researchers and engineers aim to refine and optimize tasks like object detection, image classification, and video summarization. This approach allows the algorithms to learn and adapt their strategies based on the feedback received during their interactions with diverse visual data, ultimately leading to more robust and efficient computer vision solutions.\n",
    "\n",
    "These are just a few examples of the many use cases of reinforcement learning. As RL continues to develop, it is likely to be applied to an even wider range of problems in the future.\n",
    "\n",
    "# The Reinforcement Learning Process ü§ñüîÅ\n",
    "![enter image description here](https://live.staticflickr.com/65535/53401957471_5bafe42278_z.jpg)\n",
    "\n",
    "1.  **Agent and Environment:**\n",
    "    \n",
    "    -   There is an agent that makes decisions and interacts with an environment. The environment is the external system with which the agent interacts, and it provides feedback to the agent in the form of rewards.\n",
    "2.  **State (S):**\n",
    "    \n",
    "    -   At each time step, the environment is in a certain state. A state is a representation of the current situation or configuration of the environment.\n",
    "3.  **Action (A):**\n",
    "    \n",
    "    -   The agent, based on its current state, takes an action. Actions are the decisions or moves made by the agent that can influence the state of the environment.\n",
    "4.  **Reward ( R ):**\n",
    "    \n",
    "    -   After taking an action, the environment provides feedback to the agent in the form of a reward. The reward is a numerical value that indicates the immediate benefit or cost associated with the taken action.\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "## Observations/States\n",
    "\n",
    "In Reinforcement Learning, the concept of \"observation\" or \"state\" refers to the information that the learning agent perceives from its environment at a given point in time. This information serves as the basis for the agent to make decisions and take actions.\n",
    "\n",
    "### _State s_\n",
    "a state represents a comprehensive snapshot or description of the entire state of the world within the environment. This concept is particularly relevant in fully observed environments, where there is no hidden information. In such settings, the state encapsulates all the relevant information needed for the learning agent to make decisions and take actions.\n",
    "\n",
    "![enter image description here](https://www.researchgate.net/publication/220543359/figure/fig1/AS:276849751019526@1443017532817/A-snapshot-of-the-Pac-Man-game.png)\n",
    "\n",
    "\n",
    "![Chess](data:image/png;base64,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)\n",
    "\n",
    "**a complete description of the state of the world** (there is no hidden information). In a fully observed environment.\n",
    "\n",
    "\n",
    "### _Observation o_\n",
    "An observation can be considered a partial description of the world because it typically provides the agent with a subset of information relevant to its current state.\n",
    "\n",
    "![enter image description here](data:image/jpeg;base64,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)\n",
    "\n",
    "![enter image description here](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRAsMfmRuo9FKcrqhku2RBWTRex6A-2udRY5NFBZlayCmp14shXg3_vhw1I52cm)\n",
    "\n",
    "## Action Space\n",
    "In Reinforcement Learning, the \"action space\" refers to the set of all possible actions that an agent can take in a given environment. It represents the range of decisions or moves that the agent is allowed to make at any given point in time.\n",
    "\n",
    "**Discrete Action Space:** In some environments, the agent can take a finite and distinct set of actions. For example, in a board game like chess, the action space consists of discrete moves like moving a piece to a specific square. In flappy bird, the faby has only two possible actions, moving up and moving down.  The number of possible actions is  **finite**. \n",
    "\n",
    "**Continuous Action Space:** In other cases, the action space is continuous, allowing the agent to choose from an infinite set of possible actions. For instance, in a robotic control task, the actions might involve continuous adjustments to motor speeds or joint angles. In a self driving car actions may includes steering angles, throttle adjustments, braking intensity, turn signal activation, velocity control, lane change maneuvers, and emergency response parameters. The number of possible actions is **infinite**.\n",
    "\n",
    "\n",
    "## Rewards and the discounting\n",
    "The reward is fundamental in Reinforcement Learning (RL) because it serves as the crucial feedback mechanism that guides the learning process.\n",
    "In RL literature, rewards at a time instant _t_ are typically denoted as _Rt_.\n",
    "Thus, the total rewards (Cummulative reward) earned in an episode is given by _R = r1+ r2 + ... + rt_, where _t_ is the length of the episode or the reward at each time step  (which can be finite or infinite).\n",
    "\n",
    "![enter image description here](https://cdn-media-1.freecodecamp.org/images/0*ylz4lplMffGQR_g3.)\n",
    "\n",
    "which is equivalent:\n",
    "\n",
    "![enter image description here](https://cdn-media-1.freecodecamp.org/images/1*AFAuM1Y8zmso4yB5mOApZA.png)\n",
    "\n",
    "In practice, the simple addition of rewards is not a straightforward process. Rewards occurring earlier in a sequence, such as at the beginning of a game, hold greater predictability and likelihood than those in the distant future.\n",
    "\n",
    "![enter image description here](https://cdn-media-1.freecodecamp.org/images/1*tciNrjN6pW60-h0PiQRiXg.png)\n",
    "\n",
    "Let say your agent is this small mouse and your opponent is the cat. Your goal is to eat the maximum amount of cheese before being eaten by the cat.\n",
    "\n",
    "As we can see in the diagram, it‚Äôs more probable to eat the cheese near us than the cheese close to the cat (the closer we are to the cat, the more dangerous it is).\n",
    "\n",
    "As a consequence, the reward near the cat, even if it is bigger (more cheese), will be discounted. We‚Äôre not really sure we‚Äôll be able to eat it.\n",
    "\n",
    "In Reinforcement Learning (RL), the concept of discounting is employed through a parameter known as the discount factor, denoted as Œ≥, where 0 ‚â§ Œ≥ ‚â§ 1. Most of the time between **0.95 and 0.99**. The reward at a given time, rt, is multiplied by Œ≥ raised to a power . A Œ≥ value of 0 renders the agent myopic, prioritizing immediate rewards only, while a Œ≥ value of 1 makes the agent excessively far-sighted, potentially delaying the achievement of the final goal. To strike a balance, a Œ≥ value within the exclusive range of 0 to 1 is commonly used. This ensures that the agent neither excessively focuses on short-term gains nor procrastinates its actions excessively. The discount factor, Œ≥, plays a pivotal role in guiding the agent to optimize its actions for maximizing the total discounted rewards, Rt, from a given time instant t. The relationship is expressed as the product of rt and Œ≥ raised to a power.\n",
    "\n",
    "![enter image description here](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/rewards_4.jpg)\n",
    "\n",
    "##  Type of tasks\n",
    "\n",
    "A task is an **instance** of a Reinforcement Learning problem. We can have two types of tasks: **episodic** and **continuing**.\n",
    "\n",
    "### Episodic task\n",
    "\n",
    "**episodic tasks** are those with a clear beginning and end. Each episode is a self-contained sequence of interactions between the agent and the environment, where the agent takes actions, receives rewards, and eventually reaches a **terminal state** that signals the end of the episode. The next episode then starts the agent afresh in the initial state, independent of the previous episode.\n",
    "\n",
    "Here are some key characteristics of episodic tasks:\n",
    "\n",
    "-   **Discrete episodes:** The task is naturally divided into distinct episodes, with clear start and end points.\n",
    "-   **Terminal states:** Each episode ends in a terminal state, where the agent can no longer take any actions.\n",
    "-   **Independent episodes:** The outcomes of one episode do not affect the initial state or rewards of the next episode.\n",
    "-   **Reward structure:** Rewards are typically received at the end of the episode or at specific points within the episode.\n",
    "\n",
    "\n",
    "#### Examples\n",
    "\n",
    " **Solving a maze:**  Navigating a maze from start to finish is an episodic task. Each attempt to solve the maze is an episode, and the agent receives a reward for reaching the goal state.\n",
    " \n",
    "![enter image description here](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQkr_nRfkikKhvwTNjxry7fHLc9ljet7IzavA&usqp=CAU)\n",
    "\n",
    "\n",
    " **Robot manipulation:**  A robot learning to pick up and place an object is an episodic task. Each attempt to pick up and place the object is an episode, and the agent receives a reward for successful completion.\n",
    "\n",
    "### Continuing tasks\n",
    "\n",
    "**Continuing tasks**  are those that **do not have a clear end point**. The agent interacts with the environment indefinitely, without reaching a terminal state or restarting from a fixed initial state. This means the agent must continuously make decisions and adapt its behavior over time to optimize its performance.\n",
    "\n",
    "**Here are some key characteristics of continuing tasks:**\n",
    "\n",
    "-   **No terminal states:** There's no specific state that signals the end of the task. The agent continues interacting with the environment indefinitely.\n",
    "-   **No episodic resets:** The agent doesn't start afresh from a fixed initial state after a certain number of steps or actions. It must learn and adapt within a continuous stream of interactions.\n",
    "-   **Long-term goals:** The agent's goal is often to maximize its cumulative reward over the long run, rather than just achieving a specific goal state.\n",
    "\n",
    "\n",
    "#### Examples\n",
    "\n",
    "-   **Online game playing:** An agent playing a multiplayer online game where the game never ends and the goal is to continuously improve performance.\n",
    "\n",
    "-   **Financial market prediction:** Adapting to evolving market conditions, identifying patterns, and making trading decisions in real-time.\n",
    "\n",
    "In these scenarios, **The agent keeps running until we decide to stop it.**\n",
    "\n",
    "## The Exploration/Exploitation trade-off\n",
    "The **exploration-exploitation tradeoff** is a fundamental concept in decision-making, especially in reinforcement learning (RL). It refers to the dilemma of balancing two opposing strategies:\n",
    "\n",
    "-   **Exploration:** Trying new options and actions to gather information and discover potentially better alternatives. (trying random actions in order to **find more information about the environment.**)\n",
    "\n",
    "-   **Exploitation:** Focusing on the known best options based on past experiences to maximize immediate rewards. (**exploiting known information to maximize the reward.**)\n",
    "\n",
    "**Example**\n",
    "\n",
    "![enter image description here](https://cdn-media-1.freecodecamp.org/images/1*APLmZ8CVgu0oY3sQBVYIuw.png)\n",
    "\n",
    "In this game, our mouse can have an infinite amount of small cheese (+1 each). But at the top of the maze there is a gigantic sum of cheese (+1000).\n",
    "\n",
    "However, if we only focus on reward, our agent will never reach the gigantic sum of cheese. Instead, it will only exploit the nearest source of rewards, even if this source is small (exploitation).\n",
    "\n",
    "But if our agent does a little bit of exploration, it can find the big reward.\n",
    "\n",
    "This is what we call the exploration/exploitation trade off. We must define a rule that helps to handle this trade-off. \n",
    "\n",
    "**Financial Investment:**\n",
    "-   **Exploration:** Investing in emerging markets or new industries to potentially achieve higher returns.\n",
    "-   **Exploitation:** Investing in established, stable stocks or bonds with historically reliable returns to minimize risk.\n",
    "\n",
    "## Reinforcement learning (RL) solution methods\n",
    "\n",
    "### **The Policy œÄ**:\n",
    "\n",
    "a **policy** (œÄ) is the \"brain\" of your agent, dictating how it chooses actions in different situations. It's a **function** that maps a given state (s) of the environment to an action (a) the agent should take.\n",
    "\n",
    "Think of it this way: you're navigating a maze. Each point in the maze is a state. Your policy would determine which direction you should turn at each point (left, right, forward) based on what you've learned about the maze and the potential rewards/penalties associated with each option.\n",
    "\n",
    "so essentially the policy is the **brain** of our agent.\n",
    "\n",
    "**the policy function**, which we aim to discover through training. Our ultimate objective is to identify the **optimal policy**, represented by œÄ*, that maximizes the expected reward when the agent follows it.\n",
    "\n",
    "We can train our agent to discover the optimal policy œÄ* through two distinct approaches:\n",
    "-   **Policy-Based Methods:**  These methods directly coach the agent on which actions to take within each state, leading to a refined action-selection policy.\n",
    "-   **Value-Based Methods:**  Here, the agent learns to evaluate the relative value of different states. This knowledge then guides its actions, as it prioritizes choices that steer it towards states deemed more valuable.\n",
    "\n",
    "## Policy-Based Methods\n",
    "\n",
    "In Policy-Based methods, **we learn a policy function directly.**\n",
    "**Policy-Based Methods** prioritize direct guidance: they focus on crafting a policy function that seamlessly maps each state to the optimal action.\n",
    "\n",
    "Imagine an agent equipped with an internal playbook, meticulously crafted through Policy-Based methods. This playbook empowers the agent to make confident decisions by directly consulting it for the best course of action in any given situation.\n",
    "\n",
    "![enter image description here](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/policy_2.jpg)\n",
    "##   \n",
    "\n",
    "**Deterministic vs. Probabilistic Policies in Reinforcement Learning**\n",
    "\n",
    "When training your agent to find the optimal policy (œÄ*), you have two main options:  **deterministic policies** and **probabilistic policies**. Let's break down the key differences:\n",
    "\n",
    "##   \n",
    "Deterministic vs. Probabilistic Policies in Reinforcement Learning\n",
    "\n",
    "When training your agent to find the optimal policy (œÄ*), you have two main options:  **deterministic policies** and **probabilistic policies**. Let's break down the key differences:\n",
    "\n",
    "**Deterministic Policy:**\n",
    "\n",
    "-   **Concept:** This type of policy maps each state to a single,  **unambiguously chosen** action.\n",
    "-   **Think of it like a strict rulebook:** No matter the situation, the agent performs the **predefined action** indicated by the policy.\n",
    "\n",
    "![enter image description here](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/policy_3.jpg)\n",
    "\n",
    "**Probabilistic Policy:**\n",
    "\n",
    "-   **Concept:** This type of policy maps each state to a **probability distribution** over the possible actions.\n",
    "-   **Think of it like a weighted suggestion box:** While it leans towards certain actions based on their potential rewards, it allows for some **stochasticity** or randomness.\n",
    "\n",
    "![enter image description here](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/policy_5.jpg)\n",
    "\n",
    "## Value-based methods\n",
    "In value-based methods, instead of learning a policy function, we **learn a value function** that maps a state to the expected value **of being at that state.**\n",
    "\n",
    "Here's a clearer explanation of value-based methods in reinforcement learning:**\n",
    "\n",
    "**Imagine a treasure hunter navigating a jungle.** Instead of relying on a detailed map (policy function) that dictates every step, they carry a compass that points towards valuable treasures (value function). This compass guides their choices, leading them to the most rewarding paths.\n",
    "In value-based methods, we focus on learning a **value function**. This function acts like a compass, assigning a numerical score (value) to each state in the environment. Higher scores indicate states that are more likely to lead to long-term rewards.\n",
    "\n",
    "The value of a state is the **expected discounted return** the agent can get if it **starts in that state, and then acts according to our policy.**\n",
    "\n",
    "![enter image description here](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/value_1.jpg)\n",
    "\n",
    "**Here is an example**\n",
    "\n",
    "![enter image description here](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/value_2.jpg)\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "-   Value-based methods focus on evaluating states, not directly choosing actions.\n",
    "-   The value function guides decision-making by indicating which states are most valuable in the long run.\n",
    "-   The policy typically involves pursuing the highest-valued states, leading to rewarding outcomes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a2efd-0f63-4895-9f90-e95d7708a5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
